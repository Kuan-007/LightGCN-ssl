{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13d35d3-4d54-4d33-84ab-64f0e8c23674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 读取 u.data 文件\n",
    "data = pd.read_csv('ml-1m/ratings.dat', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# 2. 创建用户和物品的映射\n",
    "user_mapping = {org_id: remap_id for remap_id, org_id in enumerate(data['user_id'].unique())}\n",
    "item_mapping = {org_id: remap_id for remap_id, org_id in enumerate(data['item_id'].unique())}\n",
    "\n",
    "# 3. 映射用户和物品 ID\n",
    "data['user_remap_id'] = data['user_id'].map(user_mapping)\n",
    "data['item_remap_id'] = data['item_id'].map(item_mapping)\n",
    "\n",
    "# 4. 创建空的训练集和测试集\n",
    "train_dict = {user: [] for user in user_mapping.values()}\n",
    "test_dict = {user: [] for user in user_mapping.values()}\n",
    "\n",
    "# 5. 按照用户进行分组，并划分训练集和测试集\n",
    "for user, group in data.groupby('user_remap_id'):\n",
    "    group = group.sort_values('timestamp')  # 按时间排序\n",
    "    if len(group) > 1:\n",
    "        # 最后一个交互作为测试集\n",
    "        train_dict[user] = group.iloc[:-1]['item_remap_id'].tolist()\n",
    "        test_dict[user] = group.iloc[-1:]['item_remap_id'].tolist()\n",
    "    else:\n",
    "        # 如果只有一个交互，全部作为训练集\n",
    "        train_dict[user] = group['item_remap_id'].tolist()\n",
    "\n",
    "# 6. 保存 train.txt 文件\n",
    "with open('train.txt', 'w') as train_file:\n",
    "    for user, items in train_dict.items():\n",
    "        line = f\"{user} \" + \" \".join(map(str, items))\n",
    "        train_file.write(line + \"\\n\")\n",
    "\n",
    "# 7. 保存 test.txt 文件\n",
    "with open('test.txt', 'w') as test_file:\n",
    "    for user, items in test_dict.items():\n",
    "        if items:  # 只有在存在测试集数据时写入\n",
    "            line = f\"{user} \" + \" \".join(map(str, items))\n",
    "            test_file.write(line + \"\\n\")\n",
    "\n",
    "# 8. 保存用户和物品映射文件\n",
    "user_list = pd.DataFrame(list(user_mapping.items()), columns=['org_id', 'remap_id'])\n",
    "item_list = pd.DataFrame(list(item_mapping.items()), columns=['org_id', 'remap_id'])\n",
    "\n",
    "user_list.to_csv('user_list.txt', sep='\\t', index=False, header=False)\n",
    "item_list.to_csv('item_list.txt', sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef93a25-a2d5-4a66-b896-7ea9f4084f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成。结果已保存到 ml-1m/ml-100k.train\n"
     ]
    }
   ],
   "source": [
    "def convert_data(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            numbers = line.strip().split()\n",
    "            user_id = numbers[0]\n",
    "            item_ids = numbers[1:]\n",
    "            \n",
    "            for item_id in item_ids:\n",
    "                outfile.write(f\"{user_id},{item_id}\\n\")\n",
    "\n",
    "\n",
    "input_file = \"ml-1m/train.txt\"\n",
    "output_file = \"ml-1m/ml-1m.train\"\n",
    "convert_data(input_file, output_file)\n",
    "print(f\"转换完成。结果已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4720821-a015-476c-97a3-cd912661d017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已保存为 ml-1m/ml-1m.test\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 test.txt 文件\n",
    "input_file = 'ml-1m/test.txt'\n",
    "output_file = 'ml-1m/ml-1m.test'\n",
    "\n",
    "data = []\n",
    "with open(input_file, 'r') as f:\n",
    "    for line in f:\n",
    "        items = line.strip().split()\n",
    "        user = items[0]  # 获取用户编号\n",
    "        for item in items[1:]:  # 获取物品编号\n",
    "            data.append([user, item])  # 将用户与物品组合\n",
    "\n",
    "# 将数据转换为 DataFrame\n",
    "df = pd.DataFrame(data, columns=['user', 'item'])\n",
    "\n",
    "# 将 DataFrame 导出为逗号分隔的文件\n",
    "df.to_csv(output_file, sep=',', header=False, index=False)\n",
    "\n",
    "print(f\"文件已保存为 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61750383-be5b-43ea-8cd1-5d627ac9415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_predictions(result_file, test_file, output_file):\n",
    "    # Read the result.txt file into a dictionary of user ratings (as a list of floats)\n",
    "    result_dict = {}\n",
    "    with open(result_file, 'r') as rf:\n",
    "        current_user_id = None\n",
    "        current_ratings = []\n",
    "\n",
    "        for line in rf:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace\n",
    "\n",
    "            # Check if the line contains user ID and ratings start\n",
    "            if '[' in line:\n",
    "                if current_user_id is not None:  # Save the previous user if we were reading one\n",
    "                    result_dict[current_user_id] = current_ratings\n",
    "\n",
    "                # Split the line on the first '['\n",
    "                user_id_part, ratings_part = line.split('[', 1)\n",
    "                current_user_id = int(user_id_part.strip())\n",
    "                current_ratings = [float(x) for x in ratings_part.strip().rstrip(']').split()]\n",
    "            elif current_user_id is not None:  # Continue collecting ratings for the current user\n",
    "                current_ratings.extend(float(x) for x in line.strip().rstrip(']').split())\n",
    "\n",
    "            # Check if we reach the end of the ratings for the current user\n",
    "            if ']' in line:\n",
    "                result_dict[current_user_id] = current_ratings\n",
    "                current_user_id = None\n",
    "                current_ratings = []\n",
    "\n",
    "        # Handle the last user if the file doesn't end with a closing bracket\n",
    "        if current_user_id is not None:\n",
    "            result_dict[current_user_id] = current_ratings\n",
    "\n",
    "    # Debug: print the populated result_dict\n",
    "    print(\"Populated result_dict:\", result_dict)\n",
    "\n",
    "    # Open the test.txt file and prediction.txt file\n",
    "    with open(test_file, 'r') as tf, open(output_file, 'w') as pf:\n",
    "        for line in tf:\n",
    "            user_id, item_id = map(int, line.strip().split())\n",
    "            print(f\"Checking user_id: {user_id}, item_id: {item_id}\")  # Debugging output\n",
    "            \n",
    "            # Check if the user exists in result_dict and extract the item rating\n",
    "            if user_id in result_dict:\n",
    "                if item_id < len(result_dict[user_id]):\n",
    "                    item_rating = result_dict[user_id][item_id]\n",
    "                    pf.write(f'{user_id} {item_id} {item_rating}\\n')\n",
    "                else:\n",
    "                    pf.write(f'{user_id} {item_id} -\\n')  # Item ID out of range\n",
    "            else:\n",
    "                pf.write(f'{user_id} {item_id} -\\n')  # User is missing\n",
    "\n",
    "# Define file paths\n",
    "result_file = 'result.txt'\n",
    "test_file = 'ml-100k/test.txt'\n",
    "output_file = 'prediction.txt'\n",
    "\n",
    "# Call the function\n",
    "extract_predictions(result_file, test_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c7cde8-d13d-466e-a2b7-0fafedc82d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34090\\AppData\\Local\\Temp\\ipykernel_526300\\3793558726.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. 读取 u.data 文件\n",
    "data = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# 2. 创建用户和物品的映射\n",
    "user_mapping = {org_id: remap_id for remap_id, org_id in enumerate(data['user_id'].unique())}\n",
    "item_mapping = {org_id: remap_id for remap_id, org_id in enumerate(data['item_id'].unique())}\n",
    "\n",
    "# 3. 映射用户和物品 ID\n",
    "data['user_remap_id'] = data['user_id'].map(user_mapping)\n",
    "data['item_remap_id'] = data['item_id'].map(item_mapping)\n",
    "\n",
    "# 4. 创建空的训练集和测试集\n",
    "train_dict = {user: [] for user in user_mapping.values()}\n",
    "test_dict = {user: [] for user in user_mapping.values()}\n",
    "\n",
    "# 5. 按照用户进行分组，并划分训练集和测试集（80% 训练集，20% 测试集）\n",
    "for user, group in data.groupby('user_remap_id'):\n",
    "    group = group.sort_values('timestamp')  # 按时间排序\n",
    "    n_interactions = len(group)\n",
    "    split_point = int(n_interactions * 0.8)  # 80% 的数据作为训练集\n",
    "    \n",
    "    if n_interactions > 1:\n",
    "        train_items = group.iloc[:split_point]['item_remap_id'].tolist()\n",
    "        test_items = group.iloc[split_point:]['item_remap_id'].tolist()\n",
    "        train_dict[user] = train_items\n",
    "        test_dict[user] = test_items\n",
    "    else:\n",
    "        # 如果只有一个交互，全部作为训练集\n",
    "        train_dict[user] = group['item_remap_id'].tolist()\n",
    "\n",
    "# 6. 保存 train.txt 文件\n",
    "with open('train.txt', 'w') as train_file:\n",
    "    for user, items in train_dict.items():\n",
    "        line = f\"{user} \" + \" \".join(map(str, items))\n",
    "        train_file.write(line + \"\\n\")\n",
    "\n",
    "# 7. 保存 test.txt 文件\n",
    "with open('test.txt', 'w') as test_file:\n",
    "    for user, items in test_dict.items():\n",
    "        if items:  # 只有在存在测试集数据时写入\n",
    "            line = f\"{user} \" + \" \".join(map(str, items))\n",
    "            test_file.write(line + \"\\n\")\n",
    "\n",
    "# 8. 保存用户和物品映射文件\n",
    "user_list = pd.DataFrame(list(user_mapping.items()), columns=['org_id', 'remap_id'])\n",
    "item_list = pd.DataFrame(list(item_mapping.items()), columns=['org_id', 'remap_id'])\n",
    "\n",
    "user_list.to_csv('user_list.txt', sep='\\t', index=False, header=False)\n",
    "item_list.to_csv('item_list.txt', sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e418e34-0200-469b-9f4c-37ed0fa4a2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
